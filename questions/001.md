### Spark内存相关

[来源链接](https://www.unraveldata.com/common-reasons-spark-applications-slow-fail-part-1/)

Spark是以内存为中心的框架，所以会遇到很多内存方面的问题。

#### 1、dirver OOM

##### 1.1、`collect()`太多的数据

`collect()`会将数据拉倒driver进行处理。

一般driver不进行繁重的操作，只控制主流程，如果executors的配置更好，可以考虑将`collect`操作改为executor执行的操作。比如，

```scala
val result = dataFrame.collect()//driver collect result
saveToCsvFile(result, "/file/path")

// will assign an executor to collect the result,assuming are better provisioned.
dataFrame.repartition(1).write.csv("/file/path")
```

##### 1.2、广播太多的数据

在进行广播之前，广播的数据（或表）会被物化（materialized）到driver节点。

另外，在启用`spark.sql.autoBroadcastJoinThreshold`自动广播时，如果`spark.sql.autoBroadcastJoinThreshold`的值过大，连接查询的表（一个、甚至多个）会被进行广播，从而导致大量数据被拉到driver中。

如果因为连接查询广播大量数据导致driver OOM，可以考虑减小`spark.sql.autoBroadcastJoinThreshold`以更多地使用内存友好的sort merge join。

##### 1.3、分配的driver内存太小

##### 相关参数

**spark.driver.maxResultSize**，限制每个Spark行动操作（比如，collect）所有分区序列化结果的总大小。至少1M，如果是0则不限制大小。如果jobs的行动操作的总大小超过这个限制，job会被放弃。如果限制过大，可能会导致Driver OOM（视`spark.driver.memory`和memory overhead的大小而定）。设置适当，可以防止driver 发生OOM的错误。

#### 2、Executor OOM

##### 2.1、高并发

Spark jobs或者查询是被拆分为多个stages的，每个stage被进而拆分为tasks。tasks的数量依赖于多种因子，比如执行的stage、读取的数据源。如果是map stage（SQL中的Scan阶段），一般由底层数据源的分区决定。

比如，如果一个hive ORC表有2000分区，那么不考虑分区修剪（partition pruning）的情况下，读取这个表的map stage 会创建 2000 个 tasks。如果是reduce stage（Shuffle stage），那么Spark会对RDD使用`spark.default.parallelism`设置，或者对Dataset使用`spark.sql.shuffle.partitions`设置来决定tasks的数量。每个executor并行执行多少个tasks由`spark.exeuctor.cores`属性决定。如果这个值不考虑合理的内存而设置的太大，executors可能会OOM。

假如，在执行一个对 HDFS 文件或者 Parquet/ORC 表的 map task 或者 SQL 的Scan阶段。对于 HDFS 文件，每个Spark task 会读取一个128M的block的数据。所以如果 10 个并行的tasks在运行，需要的仅仅用于分区数据存储的内存将是 128 * 10 M。这还是没有考虑数据压缩的情况，考虑导数据的解压缩，根据压缩算法的不同数据量可能会显著的膨胀。

Spark 以向量化的格式（vectorized format）读取 Parquet。简而言之，Spark 的每个 task 从 Parquet 文件中逐批次地（batch by batch）读取数据。Parquet 是面向列的（columnar），这些批次是由列构成的。在执行某一列的操作之前，它会累积一定量的列数据在内存中。这意味着 Spark 需要一些数据结构和账簿（bookkeeping）来保存这么多的数据。另外，编码技术（比如，字典编码dictionary encoding）有一些状态保存在内存中。所有这些都需要内存。

所以，并发越大，开销越大。如果再涉及到 broadcast join，广播变量也需要更多的内存。

##### 2.2、低效率的查询

Spark 的 Catalyst 引擎会尽量对查询进行优化，但是如果查询很糟糕，它也是无能为力的。比如，查询 Parquet/ORC 表的所有列。就像上一小节介绍的，每一列都需要一些在内存中的列批次状态。查询的列越多，开销越大。

应该尽量少地读取列，尽可能的使用`filter`，以便提取更少的数据到executors。某些数据源支持分区修剪。如果查询可以转换为使用分区字段，那么将可以大量地减少读取的数据量。

##### 2.3、配置不正确

内存和缓存配置错误也会导致 Spark 应用失败和缓慢。

###### 2.3.1、Executor & Driver Memory

每个应用的内存需要不同，根据需要每个应用配置也不同。要根据应用的负载配置正确的 `spark.executor.memory` 和 `spark.driver.memory`。

###### 2.3.2、Memory overhead

有时，不是 executor 内存，而是 YARN 容器内存开销导致 OOM，或者节点被 YARN 杀死。YARN Kill 消息通常如下：

```
[pid=<pid>,containerID=<container_ID>] is running beyond physical memory limits. Current usage: 1.5 GB of 1.5 GB physical memory used; 4.6 GB of 3.1 GB virtual memory used. Killing container.
```

YARN 在容器中运行 Spark 组件，比如 driver 和 executors。Overhead 内存是用于 JVM overheads、 interned string和其他 JVM元数据的非堆内存，它属于YARN 容器内存（YARN 容器内存也是允许范围内动态分配的）的一部分，但是不属于 executor 内存。遇到这种情况，需要配置`spark.yarn.executor.memoryOverhead`为一个合适的值。一般应该为 overhead 分配总的 exectors 内存的 10%。

另外有一个相关参数`yarn.scheduler.maximum-allocation-mb`表示的是每个 YARN 容器能够申请到的最大内存，一般是集群统一配置。

综上，executor 执行所需要占用的内存是 为executor 分配的 executor-memory 与 `spark.yarn.executor.memoryOverhead` 之和，executor 执行占用的内存应该小于 `yarn.scheduler.maximum-allocation-mb`。

类似地，有一个`spark.driver.memoryOverhead`参数。

###### 2.3.3、caching Memory

如果应用使用 Spark caching 来保存datasets，那么考虑Spark的内存管理设置是值得的。Spark 的内存管理器是以非常通用（generic）的风格编写的以迎合所有的工作负载。因此，对于特定的工作负载要进行特定的设置。

Spark 将内存需求定义为两种类型：execution 和 storage。Storage Memory 是用于caching 和在集群中传播内部数据目的的内存，execution memory是为临时结构（比如聚合的hash表，join等）而获取的，用于混洗、join、sorts和聚合运算的。在Spark 中，execution 和 storage 共享一个统一的区域（**M**）。当没有 execution 内存使用时，storage可以获取所有的可用内存，反正亦然。如有必要，execution 可以抢占（evict）storage 内存，最多只能抢占至storage 内存被压缩到一个特定的阈值（**R**）。由于实现上的复杂性，storage 不能抢占execution 内存。

`spark.memory.fraction`将 **M** 的大小表示为（JVM 堆空间 - 300MB）的一个因子，默认值是 0.6 。其余的空间（40%）是保留给用户数据结构、Spark中的内部元数据、和稀疏和异常大记录情况下应对OOM错误的安全保证的。

`spark.memory.storageFraction`将 **R** 的大小表示为一个因子（默认，0.5）。**R** 是 **M** 中的存储空间，其中缓存的数据块（blocks）不会被execution抢占。默认，其余（50%）分配给execution。

*存在上述内存池互相借用的情况，名义上的execution 和 storage内存在另一方空闲的时候可以互相借用。并且，如果storage 内存从execution 借用内存，它可以被限制到一定的限度。（此处存疑？）*不管细节上多么复杂，配置storage 内存时，应当保证有足够的 execution 内存。

如果不希望所有的缓存数据都停留在内存中，可以将`spark.memory.storageFraction`设置为较小的值，超过的数据会被处理，并且不会导致execution 内存承压。

##### 2.4、在节点管理器OOM

进行数据混洗的 Spark 应用（比如进行了 group by或join 之类的操作）会引起显著的开销。一般，数据混洗处理是由executor 进程完成的。如果executor 很忙，或者GC 负载很大，那么它将无法应对混洗请求。通过使用一个**外部的混洗服务**（external shuffle service）可以在某种程度上减轻这种问题。

外部混洗服务运行在每个工作者节点上，并且处理executors 的混洗请求。executors 可以从这些服务读取（而不是从executors读取）混洗文件。这让请求executors（requesting executors） 即使在生产executors（producing executors）被杀死或者很慢的情况下也能读取混洗文件。并且，**当开启了动态分配（dynamic allocation）时，启用外部混洗服务是强制性的**。

当使用YARN 配置 Spark 外部混洗服务时，NodeManager 其中一个辅助的（auxiliary）服务作为外部混洗服务的提供者。默认情况下，NodeManager 内存是 1 GB 左右。但是，进行重度数据混洗的应用可能因为NodeManager OOM 而失败。如果应用因为这种情况而失败，合理配置 Node Manager是很重要的。

#### 3、总结

Spark 的在内存（in-memory）处理是它强大功能的关键。因而，高效地内存管理是Spark应用和数据管道获得的最佳性能、扩展性和稳定性的关键因子。但是，Spark 默认设置通常是不足够的。对于某些应用和环境，某些关键配置参数必须正确设置以实现高性能。

有时候，有些莫名其妙的错误可能都是内存不足引起的。

有个程序，分配完 executor 后，开始 job 执行前，莫名奇妙的因为 `Receive Term signal` 结束，后来有时执行又在某些不该报错的地方报 `NullPointerException`，将 driver memory 从 4G 增加为 6G 后就正常了。难道是 driver 生成执行计划时内存不足引起的莫名错误？

